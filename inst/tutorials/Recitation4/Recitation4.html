<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Ozancan Ozdemir" />


<meta name="progressive" content="false" />
<meta name="allow-skip" content="false" />
<meta name="learnr-version-prerender" content="0.11.2" />

<title>STAT 412-Recitation 4</title>

<!-- header-includes START -->
<!-- HEAD_CONTENT -->
<!-- header-includes END -->
<!-- HEAD_CONTENT -->

<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>


<!-- taken from https://github.com/rstudio/rmarkdown/blob/de8a9c38618903627ca509f5401d50a0876079f7/inst/rmd/h/default.html#L293-L343 -->
<!-- tabsets -->
<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>
<!-- end tabsets -->


</head>

<body>
<a class='sr-only sr-only-focusable visually-hidden-focusable' href='#learnr-tutorial-content'>Skip to Tutorial Content</a>



<div class="pageContent band">
<main class="bandContent page">

<article class="topics" id="learnr-tutorial-content">

<div id="section-reminder" class="section level2">
<h2><span style="color:darkred"> <strong>Reminder</strong> </span></h2>
<p>Last week, we talked about data cleaning using</p>
<ul>
<li><p><code>stringr</code> package</p></li>
<li><p><code>deducorrect</code> package</p></li>
<li><p><code>editrules</code> package</p></li>
</ul>
<p>Install the packages using the code line given below.</p>
<ul>
<li><p><code>ISLR</code></p></li>
<li><p><code>dplyr</code></p></li>
<li><p><code>corrplot</code></p></li>
<li><p><code>PerformanceAnalytics</code></p></li>
<li><p><code>glmnet</code></p></li>
<li><p><code>GGally</code></p></li>
<li><p><code>car</code></p></li>
</ul>
<pre><code>install.packages(c(&quot;ISLR&quot;,&quot;dplyr&quot;,&quot;corrplot&quot;,&quot;PerformanceAnalytics&quot;,&quot;glmnet&quot;,&quot;GGally&quot;,&quot;car&quot;))</code></pre>
</div>
<div id="section-some-problems-appear-in-data-multicollinearity"
class="section level2">
<h2><span style="color:darkred"> <strong>Some Problems Appear in Data /
Multicollinearity</strong> </span></h2>
<div id="section-multicollinearity" class="section level3">
<h3><span style="color:darkred"> <strong>Multicollinearity</strong>
</span></h3>
<p>Linear regression is one of the most widely used modelling technique
in the prediction or forecasting area. (<code>lm()</code> used for
application in R.) When you are playing with this method, you should be
aware of the fact that the model should satisfy some theoretical
assumptions. One of the assumption of a linear model is that the
predictors, also called features, have to be <strong>linearly
independent.</strong></p>
<p><span style="color:darkred"> <strong>What if they are not
independent?</strong></span></p>
<p>If you have at least two variables that are highly correlated (<span
class="math inline">\(r&gt;=0.7\)</span>), we have a collinearity or a
multicollinearity problem.</p>
<p><strong>What is collinearity?</strong></p>
<p>If two predictors have a considerable linear relationship between
them, it is called <strong>collinearity</strong>.</p>
<p><strong>Multicollinearity refers to a situation in which two or more
explanatory variables in a multiple regression model are highly linearly
related.</strong></p>
<p>Perfect multicollinearity appears when you the model has a
independent variable which is a linear combination of other variables in
the model. For example, you have a linear model</p>
<p><span
class="math inline">\(\hat{y}=\hat{x1}+\hat{x2}+\hat{x3}\)</span>
where;</p>
<p><span class="math inline">\(\hat{x3}= a*\hat{x1}+b*\hat{x2}\)</span>
where <span class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span> are constants.</p>
<p>The variable , <span class="math inline">\(\hat{x3}\)</span>, does
not add any significant or different value than provided by <span
class="math inline">\(\hat{x1}\)</span> or <span
class="math inline">\(\hat{x2}\)</span>. The model can adjust itself to
set the parameters that this combination is taken care of while
determining the coefficients.</p>
<p>However, the appearance of a perfect multicollinearity rarely occurs.
Instead, imperfect or less than perfect multicollinearity, which is two
or more of the explanatory variables have <strong>approximate</strong>
linear association, usually occur in the practice.</p>
<p><strong>What Problems Do Multicollinearity Cause?</strong></p>
<p>The existence of a little bit multicollinearity is not a necessarily
a big problem. However, strong multicollinearity is a problem which
should be dealt with.</p>
<p>The problems that multicollinearity can cause the following problems
in the model.</p>
<ul>
<li><p>The model coefficients have incredibly high variance which makes
them unstable.</p></li>
<li><p>The coefficient with wrong sign might appear in the model. For
example, you expect that when the job level increase, the salary
increase. In other words, we expect that job level increase has a
positive effect on the salary. However, the job level variable might
have negative sign in the model.</p></li>
<li><p>It reduces the precision of the estimate coefficients, which
weakens the statistical power of your regression model. You might not be
able to trust the p values to identify independent variables that are
statistically significant. In other words, a variable which does not
have significant effect on the response seems statistically significant
or vice versa.</p></li>
<li><p>The coefficent with unreasonable value might be also appear in
the model if such a problem exists.</p></li>
<li><p>You can have more than one model which fits well to the same
data.</p></li>
</ul>
<div id="section-how-to-check-multicollinearity" class="section level4">
<h4><span style="color:darkred"> <strong>How to check
multicollinearity?</strong> </span></h4>
<p>We have both informal and formal ways to detect multicollinearity in
the regression model.</p>
<p><span style="color:blue"> <strong>Informal Ways</strong> </span></p>
<ul>
<li><strong>Scatter Plot</strong></li>
</ul>
<p>You can observe the existence of the relationship among
<strong>numerical</strong> variables through scatter plot or scatter
plot matrix.</p>
<ul>
<li><strong>Correlation Matrix</strong></li>
</ul>
<p>The Pearson Correlation Coefficient, which measures the degree of the
linear association between two numerical quantities, help you to find
out the existence of the relationship.</p>
<ul>
<li><strong>Removing or adding predictor/s to the model</strong></li>
</ul>
<p>When you remove or add a predictor or predictors to the model, if you
observe a <strong>sharp</strong> change in the value of coefficients,
this might be hint for collinearity.</p>
<p><span style="color:darkred"> <strong>Formal Ways</strong> </span></p>
<ul>
<li><strong>Variance Inflation Factor</strong></li>
</ul>
<p><img
src="https://storage.googleapis.com/onlinebilet/firma/mersin-vif-turizm-otobus-firmasi.jpg"
style="width:100.0%" /></p>
<p>The variance inflation factor (VIF) evaluates the extent of
correlation between one predictor and the other predictors in a model.
<strong>It estimates how much the variance of regression coefficient is
inflated due to multicollinearity in the model.</strong> It is used for
diagnosing collinearity/multicollinearity. Higher values signify that it
is difficult to impossible to assess accurately the contribution of
predictors to a model.</p>
<p>If VIF value is greater than <strong>10</strong>, then you have
multicollinearity problem. According to the some notes, <span
class="math inline">\(VIF&gt;5\)</span> is a clue for
multicollinearity.</p>
<div class="panel-heading tutorial-quiz-title"><span data-i18n="text.quiz">Quiz</span></div>
<div class="panel panel-default tutorial-question-container">
<div data-label="quiz44-1" class="tutorial-question panel-body">
<div id="quiz44-1-answer_container" class="shiny-html-output"></div>
<div id="quiz44-1-message_container" class="shiny-html-output"></div>
<div id="quiz44-1-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<div class="panel-heading tutorial-quiz-title"><span data-i18n="text.quiz">Quiz</span></div>
<div class="panel panel-default tutorial-question-container">
<div data-label="quiz45-1" class="tutorial-question panel-body">
<div id="quiz45-1-answer_container" class="shiny-html-output"></div>
<div id="quiz45-1-message_container" class="shiny-html-output"></div>
<div id="quiz45-1-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p><span style="color:darkred"><strong>Reference</strong></span></p>
<p><a
href="https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/">Jim
Frost -Multicollinearity in Regression Analysis: Problems, Detection,
and Solutions</a></p>
</div>
</div>
</div>
<div id="section-application" class="section level2">
<h2><span style="color:darkred"> <strong>Application</strong>
</span></h2>
<p>Please call <code>ISLR</code> package to use data of
<code>Hitters</code>.</p>
<pre><code>library(ISLR)
data(Hitters)
head(Hitters)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["AtBat"],"name":[1],"type":["int"],"align":["right"]},{"label":["Hits"],"name":[2],"type":["int"],"align":["right"]},{"label":["HmRun"],"name":[3],"type":["int"],"align":["right"]},{"label":["Runs"],"name":[4],"type":["int"],"align":["right"]},{"label":["RBI"],"name":[5],"type":["int"],"align":["right"]},{"label":["Walks"],"name":[6],"type":["int"],"align":["right"]},{"label":["Years"],"name":[7],"type":["int"],"align":["right"]},{"label":["CAtBat"],"name":[8],"type":["int"],"align":["right"]},{"label":["CHits"],"name":[9],"type":["int"],"align":["right"]},{"label":["CHmRun"],"name":[10],"type":["int"],"align":["right"]},{"label":["CRuns"],"name":[11],"type":["int"],"align":["right"]},{"label":["CRBI"],"name":[12],"type":["int"],"align":["right"]},{"label":["CWalks"],"name":[13],"type":["int"],"align":["right"]},{"label":["League"],"name":[14],"type":["fct"],"align":["left"]},{"label":["Division"],"name":[15],"type":["fct"],"align":["left"]},{"label":["PutOuts"],"name":[16],"type":["int"],"align":["right"]},{"label":["Assists"],"name":[17],"type":["int"],"align":["right"]},{"label":["Errors"],"name":[18],"type":["int"],"align":["right"]},{"label":["Salary"],"name":[19],"type":["dbl"],"align":["right"]},{"label":["NewLeague"],"name":[20],"type":["fct"],"align":["left"]}],"data":[{"1":"293","2":"66","3":"1","4":"30","5":"29","6":"14","7":"1","8":"293","9":"66","10":"1","11":"30","12":"29","13":"14","14":"A","15":"E","16":"446","17":"33","18":"20","19":"NA","20":"A","_rn_":"-Andy Allanson"},{"1":"315","2":"81","3":"7","4":"24","5":"38","6":"39","7":"14","8":"3449","9":"835","10":"69","11":"321","12":"414","13":"375","14":"N","15":"W","16":"632","17":"43","18":"10","19":"475.0","20":"N","_rn_":"-Alan Ashby"},{"1":"479","2":"130","3":"18","4":"66","5":"72","6":"76","7":"3","8":"1624","9":"457","10":"63","11":"224","12":"266","13":"263","14":"A","15":"W","16":"880","17":"82","18":"14","19":"480.0","20":"A","_rn_":"-Alvin Davis"},{"1":"496","2":"141","3":"20","4":"65","5":"78","6":"37","7":"11","8":"5628","9":"1575","10":"225","11":"828","12":"838","13":"354","14":"N","15":"E","16":"200","17":"11","18":"3","19":"500.0","20":"N","_rn_":"-Andre Dawson"},{"1":"321","2":"87","3":"10","4":"39","5":"42","6":"30","7":"2","8":"396","9":"101","10":"12","11":"48","12":"46","13":"33","14":"N","15":"E","16":"805","17":"40","18":"4","19":"91.5","20":"N","_rn_":"-Andres Galarraga"},{"1":"594","2":"169","3":"4","4":"74","5":"51","6":"35","7":"11","8":"4408","9":"1133","10":"19","11":"501","12":"336","13":"194","14":"A","15":"W","16":"282","17":"421","18":"25","19":"750.0","20":"A","_rn_":"-Alfredo Griffin"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre><code>dim(Hitters)</code></pre>
<pre><code>## [1] 322  20</code></pre>
<pre><code>names(Hitters)
#Functions to get or set the names of an object.</code></pre>
<pre><code>##  [1] &quot;AtBat&quot;     &quot;Hits&quot;      &quot;HmRun&quot;     &quot;Runs&quot;      &quot;RBI&quot;       &quot;Walks&quot;    
##  [7] &quot;Years&quot;     &quot;CAtBat&quot;    &quot;CHits&quot;     &quot;CHmRun&quot;    &quot;CRuns&quot;     &quot;CRBI&quot;     
## [13] &quot;CWalks&quot;    &quot;League&quot;    &quot;Division&quot;  &quot;PutOuts&quot;   &quot;Assists&quot;   &quot;Errors&quot;   
## [19] &quot;Salary&quot;    &quot;NewLeague&quot;</code></pre>
<hr />
<p><span style="color:darkred"> Description </span></p>
<p>It is a data frame having 322 rows and 20 variables</p>
<ul>
<li><p>LEAGUE : Players league</p></li>
<li><p>ATBAT : Times at Bat: Number of official plate appearances by a
hitter. It counts as an official at bat as long as the batter does not
walk, sacrifice, get hit by a pitch or reach base due to catchers
interference.</p></li>
<li><p>HITS : Hits</p></li>
<li><p>HMRUN : Home Runs</p></li>
<li><p>RUNS : The number of runs scored by a player. A run is scored by
an offensive player who advances from batter to runner and touches
first, second, third and home base in that order without being put
out.</p></li>
<li><p>RBI Runs Batted In: A hitter earns a run batted in when he drives
in a run via a hit, walk, sacrifice (bunt or fly) fielders choice, hit
batsman or on an error (when the official scorer rules that the run
would have scored anyway).</p></li>
<li><p>WALKS : Walks: A walk base on balls is an award of first base
granted to a batter who receives four pitches outside the strike
zone.</p></li>
<li><p>YEARS : Years in the Major Leagues. As far as we can tell, this
counts all years a player has actually played in the Major Leagues, not
necessarily consectutive. Rookie contracts 4Yrs.</p></li>
<li><p>CATBAT : Career Times at Bat</p></li>
<li><p>CHITS : Career Hits</p></li>
<li><p>CHMRUN : Career Home Runs</p></li>
<li><p>CRUNS : Career Runs Scored</p></li>
<li><p>CRBI : Career Runs Batted In POSITION Players position(s). See
list of codes used below under Coding for some of the variables. (You
are free to recode these as you see fit.)</p></li>
<li><p>PUTOUTS : Put Outs. A put out is credited when a fielder causes a
batter or runner to be, well, put out; e.g., catches the batters fly
ball, tags a base runner out before he reaches the base, etc.</p></li>
<li><p>ASSISTS : An assist is credited when a fielder assists in a play
causing a player to be put out; e.g.,</p></li>
<li><p>ERRORS : Errors</p></li>
<li><p>SALARY : 1987 Annual salary on opening day (in 1000$)
<strong>Variable of Interest!/Target Variable</strong></p></li>
</ul>
<hr />
<p>First of all, we note that the Salary variable is missing for some of
the players. The <code>is.na()</code> function can be used to identify
the missing observations. It returns a vector of the same length as the
input vector, with a TRUE for any elements that are missing, and a FALSE
for non-missing elements. <code>sum()</code> function can then be used
to count all of the missing elements.</p>
<pre><code>sum(is.na(Hitters$Salary))</code></pre>
<pre><code>## [1] 59</code></pre>
<p>Hence we see that Salary is missing for 59 players. The
<code>na.omit()</code> function removes all of the rows that have
missing values in any variable. (Note that we have better ways for
handling missingness.)</p>
<pre><code>Hitters = na.omit(Hitters)
dim(Hitters)</code></pre>
<pre><code>## [1] 263  20</code></pre>
<pre><code>sum(is.na(Hitters$Salary))</code></pre>
<pre><code>## [1] 0</code></pre>
<p>No missing observation.</p>
<p><strong>Before applying shrinkage methods, we need to be sure that
the data has no missing observation. </strong></p>
<p>After get rid of the missing observations, check the class of columns
in the data.</p>
<pre><code>str(Hitters)</code></pre>
<pre><code>## &#39;data.frame&#39;:    263 obs. of  20 variables:
##  $ AtBat    : int  315 479 496 321 594 185 298 323 401 574 ...
##  $ Hits     : int  81 130 141 87 169 37 73 81 92 159 ...
##  $ HmRun    : int  7 18 20 10 4 1 0 6 17 21 ...
##  $ Runs     : int  24 66 65 39 74 23 24 26 49 107 ...
##  $ RBI      : int  38 72 78 42 51 8 24 32 66 75 ...
##  $ Walks    : int  39 76 37 30 35 21 7 8 65 59 ...
##  $ Years    : int  14 3 11 2 11 2 3 2 13 10 ...
##  $ CAtBat   : int  3449 1624 5628 396 4408 214 509 341 5206 4631 ...
##  $ CHits    : int  835 457 1575 101 1133 42 108 86 1332 1300 ...
##  $ CHmRun   : int  69 63 225 12 19 1 0 6 253 90 ...
##  $ CRuns    : int  321 224 828 48 501 30 41 32 784 702 ...
##  $ CRBI     : int  414 266 838 46 336 9 37 34 890 504 ...
##  $ CWalks   : int  375 263 354 33 194 24 12 8 866 488 ...
##  $ League   : Factor w/ 2 levels &quot;A&quot;,&quot;N&quot;: 2 1 2 2 1 2 1 2 1 1 ...
##  $ Division : Factor w/ 2 levels &quot;E&quot;,&quot;W&quot;: 2 2 1 1 2 1 2 2 1 1 ...
##  $ PutOuts  : int  632 880 200 805 282 76 121 143 0 238 ...
##  $ Assists  : int  43 82 11 40 421 127 283 290 0 445 ...
##  $ Errors   : int  10 14 3 4 25 7 9 19 0 22 ...
##  $ Salary   : num  475 480 500 91.5 750 ...
##  $ NewLeague: Factor w/ 2 levels &quot;A&quot;,&quot;N&quot;: 2 1 2 2 1 1 1 2 1 1 ...
##  - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:59] 1 16 19 23 31 33 37 39 40 42 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:59] &quot;-Andy Allanson&quot; &quot;-Billy Beane&quot; &quot;-Bruce Bochte&quot; &quot;-Bob Boone&quot; ...</code></pre>
<p>Since our main job today is to deal with multicollinearity, I would
like to omit the categorical variable.</p>
<pre><code>library(dplyr)
Hitters&lt;-Hitters%&gt;%select(-League,-Division,-NewLeague)
head(Hitters)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["AtBat"],"name":[1],"type":["int"],"align":["right"]},{"label":["Hits"],"name":[2],"type":["int"],"align":["right"]},{"label":["HmRun"],"name":[3],"type":["int"],"align":["right"]},{"label":["Runs"],"name":[4],"type":["int"],"align":["right"]},{"label":["RBI"],"name":[5],"type":["int"],"align":["right"]},{"label":["Walks"],"name":[6],"type":["int"],"align":["right"]},{"label":["Years"],"name":[7],"type":["int"],"align":["right"]},{"label":["CAtBat"],"name":[8],"type":["int"],"align":["right"]},{"label":["CHits"],"name":[9],"type":["int"],"align":["right"]},{"label":["CHmRun"],"name":[10],"type":["int"],"align":["right"]},{"label":["CRuns"],"name":[11],"type":["int"],"align":["right"]},{"label":["CRBI"],"name":[12],"type":["int"],"align":["right"]},{"label":["CWalks"],"name":[13],"type":["int"],"align":["right"]},{"label":["PutOuts"],"name":[14],"type":["int"],"align":["right"]},{"label":["Assists"],"name":[15],"type":["int"],"align":["right"]},{"label":["Errors"],"name":[16],"type":["int"],"align":["right"]},{"label":["Salary"],"name":[17],"type":["dbl"],"align":["right"]}],"data":[{"1":"315","2":"81","3":"7","4":"24","5":"38","6":"39","7":"14","8":"3449","9":"835","10":"69","11":"321","12":"414","13":"375","14":"632","15":"43","16":"10","17":"475.0","_rn_":"-Alan Ashby"},{"1":"479","2":"130","3":"18","4":"66","5":"72","6":"76","7":"3","8":"1624","9":"457","10":"63","11":"224","12":"266","13":"263","14":"880","15":"82","16":"14","17":"480.0","_rn_":"-Alvin Davis"},{"1":"496","2":"141","3":"20","4":"65","5":"78","6":"37","7":"11","8":"5628","9":"1575","10":"225","11":"828","12":"838","13":"354","14":"200","15":"11","16":"3","17":"500.0","_rn_":"-Andre Dawson"},{"1":"321","2":"87","3":"10","4":"39","5":"42","6":"30","7":"2","8":"396","9":"101","10":"12","11":"48","12":"46","13":"33","14":"805","15":"40","16":"4","17":"91.5","_rn_":"-Andres Galarraga"},{"1":"594","2":"169","3":"4","4":"74","5":"51","6":"35","7":"11","8":"4408","9":"1133","10":"19","11":"501","12":"336","13":"194","14":"282","15":"421","16":"25","17":"750.0","_rn_":"-Alfredo Griffin"},{"1":"185","2":"37","3":"1","4":"23","5":"8","6":"21","7":"2","8":"214","9":"42","10":"1","11":"30","12":"9","13":"24","14":"76","15":"127","16":"7","17":"70.0","_rn_":"-Al Newman"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Start with informal ways.</p>
<p><strong>Checking Correlation and Scatter Plot Between
Predictors</strong></p>
<p>Correlation is a statistic that measures the degree to which two
variables move in relation to each other. Large correlation is an
indication of multicollinearity.</p>
<pre><code>CorrTable&lt;-cor(Hitters)
CorrTable</code></pre>
<pre><code>##             AtBat       Hits        HmRun        Runs        RBI     Walks
## AtBat   1.0000000 0.96396913  0.555102154  0.89982910 0.79601539 0.6244481
## Hits    0.9639691 1.00000000  0.530627358  0.91063014 0.78847819 0.5873105
## HmRun   0.5551022 0.53062736  1.000000000  0.63107588 0.84910743 0.4404537
## Runs    0.8998291 0.91063014  0.631075883  1.00000000 0.77869235 0.6970151
## RBI     0.7960154 0.78847819  0.849107434  0.77869235 1.00000000 0.5695048
## Walks   0.6244481 0.58731051  0.440453717  0.69701510 0.56950476 1.0000000
## Years   0.0127255 0.01859809  0.113488420 -0.01197495 0.12966795 0.1347927
## CAtBat  0.2071663 0.20667761  0.217463613  0.17181080 0.27812591 0.2694500
## CHits   0.2253415 0.23560577  0.217495691  0.19132697 0.29213714 0.2707951
## CHmRun  0.2124215 0.18936425  0.492525845  0.22970104 0.44218969 0.3495822
## CRuns   0.2372778 0.23889610  0.258346846  0.23783121 0.30722616 0.3329766
## CRBI    0.2213932 0.21938423  0.349858379  0.20233548 0.38777657 0.3126968
## CWalks  0.1329257 0.12297073  0.227183183  0.16370021 0.23361884 0.4291399
## PutOuts 0.3096075 0.29968754  0.250931497  0.27115986 0.31206456 0.2808555
## Assists 0.3421174 0.30397495 -0.161601753  0.17925786 0.06290174 0.1025226
## Errors  0.3255770 0.27987618 -0.009743082  0.19260879 0.15015469 0.0819372
## Salary  0.3947709 0.43867474  0.343028078  0.41985856 0.44945709 0.4438673
##               Years       CAtBat       CHits      CHmRun       CRuns
## AtBat    0.01272550  0.207166254  0.22534146  0.21242155  0.23727777
## Hits     0.01859809  0.206677608  0.23560577  0.18936425  0.23889610
## HmRun    0.11348842  0.217463613  0.21749569  0.49252584  0.25834685
## Runs    -0.01197495  0.171810798  0.19132697  0.22970104  0.23783121
## RBI      0.12966795  0.278125914  0.29213714  0.44218969  0.30722616
## Walks    0.13479270  0.269449974  0.27079505  0.34958216  0.33297657
## Years    1.00000000  0.915680692  0.89784449  0.72237071  0.87664855
## CAtBat   0.91568069  1.000000000  0.99505681  0.80167609  0.98274694
## CHits    0.89784449  0.995056810  1.00000000  0.78665204  0.98454184
## CHmRun   0.72237071  0.801676089  0.78665204  1.00000000  0.82562483
## CRuns    0.87664855  0.982746941  0.98454184  0.82562483  1.00000000
## CRBI     0.86380936  0.950730141  0.94679739  0.92790264  0.94567701
## CWalks   0.83752373  0.906711655  0.89071842  0.81087827  0.92776846
## PutOuts -0.02001921  0.053392514  0.06734799  0.09382223  0.05908718
## Assists -0.08511772 -0.007897271 -0.01314420 -0.18888646 -0.03889509
## Errors  -0.15651196 -0.070477521 -0.06803583 -0.16536941 -0.09408054
## Salary   0.40065699  0.526135310  0.54890956  0.52493056  0.56267771
##                CRBI      CWalks     PutOuts      Assists       Errors
## AtBat    0.22139318  0.13292568  0.30960746  0.342117377  0.325576978
## Hits     0.21938423  0.12297073  0.29968754  0.303974950  0.279876183
## HmRun    0.34985838  0.22718318  0.25093150 -0.161601753 -0.009743082
## Runs     0.20233548  0.16370021  0.27115986  0.179257859  0.192608787
## RBI      0.38777657  0.23361884  0.31206456  0.062901737  0.150154692
## Walks    0.31269680  0.42913990  0.28085548  0.102522559  0.081937197
## Years    0.86380936  0.83752373 -0.02001921 -0.085117725 -0.156511957
## CAtBat   0.95073014  0.90671165  0.05339251 -0.007897271 -0.070477521
## CHits    0.94679739  0.89071842  0.06734799 -0.013144204 -0.068035829
## CHmRun   0.92790264  0.81087827  0.09382223 -0.188886464 -0.165369407
## CRuns    0.94567701  0.92776846  0.05908718 -0.038895093 -0.094080542
## CRBI     1.00000000  0.88913701  0.09537515 -0.096558877 -0.115316131
## CWalks   0.88913701  1.00000000  0.05816016 -0.066243445 -0.129935875
## PutOuts  0.09537515  0.05816016  1.00000000 -0.043390143  0.075305857
## Assists -0.09655888 -0.06624345 -0.04339014  1.000000000  0.703504693
## Errors  -0.11531613 -0.12993587  0.07530586  0.703504693  1.000000000
## Salary   0.56696569  0.48982204  0.30048036  0.025436136 -0.005400702
##               Salary
## AtBat    0.394770945
## Hits     0.438674738
## HmRun    0.343028078
## Runs     0.419858559
## RBI      0.449457088
## Walks    0.443867260
## Years    0.400656994
## CAtBat   0.526135310
## CHits    0.548909559
## CHmRun   0.524930560
## CRuns    0.562677711
## CRBI     0.566965686
## CWalks   0.489822036
## PutOuts  0.300480356
## Assists  0.025436136
## Errors  -0.005400702
## Salary   1.000000000</code></pre>
<p>The output is called as correlation matrix having symmetry property.
As you see from the table, the model has several predictors having large
correlation between each other. For example, the correlation between
<strong>AtBat</strong> and <strong>Hits</strong> is 0.963 which
indicates almost perfect linear relationship among the variables.</p>
<p>You can visualize this matrix to observe the relationships
easily.</p>
<pre><code>library(corrplot)
corrplot(CorrTable)
#in the function we put the correlation matrix object
</code></pre>
<p><img src="Recitation4_files/figure-html/unnamed-chunk-10-1.png" width="624" /></p>
<p>As seen, mainly we have two groups of variables that are highly
correlated with each other.</p>
<p>Also, you can draw a scatter plot of matrix with the corresponding
correlation values between the variables. There are several way to do
this, some of them are given below.</p>
<p>Note that the scatter plot matrix is an efficient tool especially you
have <span class="math inline">\(p&lt;10\)</span>, where <span
class="math inline">\(p\)</span> is the number of numerical
variables.</p>
<pre><code>library(GGally)
ggpairs(Hitters, title=&quot;correlogram with ggpairs()&quot;) </code></pre>
<p><img src="Recitation4_files/figure-html/unnamed-chunk-11-1.png" width="624" /></p>
<pre><code>library(PerformanceAnalytics)
chart.Correlation(Hitters)
#we put the dataset in the function.</code></pre>
<p><img src="Recitation4_files/figure-html/unnamed-chunk-12-1.png" width="624" /></p>
<p>Despite the output is not clear, we can still say that there are
several predictors having strong relationship.</p>
<p>Both correlation and scatter plot matrices tell us that it will not
be surprise that we may have multicollinearity in linear model.</p>
<pre><code>fit1&lt;-lm(Salary~.,data=Hitters)
#~. -&gt; consider all variables in the data</code></pre>
<pre><code>summary(fit1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Salary ~ ., data = Hitters)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -982.81 -187.84  -35.66  130.61 1947.43 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 126.10553   83.62448   1.508 0.132838    
## AtBat        -2.20302    0.63605  -3.464 0.000629 ***
## Hits          7.82776    2.40198   3.259 0.001276 ** 
## HmRun         2.16355    6.23618   0.347 0.728937    
## Runs         -2.09957    3.00849  -0.698 0.485911    
## RBI          -0.02292    2.61033  -0.009 0.993003    
## Walks         6.15106    1.84028   3.342 0.000960 ***
## Years        -2.59237   12.45401  -0.208 0.835280    
## CAtBat       -0.17628    0.13667  -1.290 0.198325    
## CHits         0.06976    0.67874   0.103 0.918221    
## CHmRun       -0.23309    1.63561  -0.143 0.886795    
## CRuns         1.61005    0.75162   2.142 0.033168 *  
## CRBI          0.80143    0.70000   1.145 0.253367    
## CWalks       -0.79394    0.33243  -2.388 0.017681 *  
## PutOuts       0.29457    0.07830   3.762 0.000211 ***
## Assists       0.38400    0.22383   1.716 0.087499 .  
## Errors       -2.87871    4.42077  -0.651 0.515539    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 319.9 on 246 degrees of freedom
## Multiple R-squared:  0.5279, Adjusted R-squared:  0.4972 
## F-statistic: 17.19 on 16 and 246 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We can say that the model is significant on the average.
(<strong>pvalue: &lt; 2.2e16</strong>)</p>
<p>The 49.7% of the variability of salary can be explained by the
predictors. (Look at Adjusted R Squared Values).</p>
<p>Atbat, Hits, Walks, Cruns, Cwalks and Putouts are the significant
predictors due to having pvalue being less than 0.05.</p>
<p>Look at the coefficient of CHmRun which is the number of home runs
during his career.</p>
<p>We expect a positive sign in front of the variable, but it has
negative sign. This makes us suspicious about the existence of
multicollinearity. In this case, please avoid interpreting the model
coefficients.</p>
<p>Continue to seek the multicollinearity in the model via
<strong>informal ways</strong>.</p>
<p><strong>Removing one or more than predictor from the
model</strong></p>
<p>When you remove one or more than one predictor from the model, you
observe a sharp change for the coefficents of the predictors. You might
have a multicollinearity problem.</p>
<pre><code>fit2&lt;-lm(Salary~. -AtBat,data=Hitters)
#please be careful about the empty space between dot and - sign after ~ sign.</code></pre>
<pre><code>summary(fit2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Salary ~ . - AtBat, data = Hitters)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -965.46 -184.66  -32.42  113.27 2040.86 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 12.38433   78.60249   0.158  0.87494    
## Hits         1.88520    1.71802   1.097  0.27358    
## HmRun        1.67559    6.37185   0.263  0.79280    
## Runs        -1.62475    3.07153  -0.529  0.59730    
## RBI         -0.96908    2.65316  -0.365  0.71523    
## Walks        4.33029    1.80243   2.402  0.01702 *  
## Years        4.79035   12.54040   0.382  0.70279    
## CAtBat      -0.36979    0.12747  -2.901  0.00406 ** 
## CHits        0.77404    0.66183   1.170  0.24331    
## CHmRun      -0.23116    1.67163  -0.138  0.89013    
## CRuns        1.19831    0.75850   1.580  0.11543    
## CRBI         0.84672    0.71529   1.184  0.23766    
## CWalks      -0.46063    0.32520  -1.416  0.15791    
## PutOuts      0.26572    0.07957   3.339  0.00097 ***
## Assists      0.30529    0.22758   1.341  0.18100    
## Errors      -4.64793    4.48785  -1.036  0.30137    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 326.9 on 247 degrees of freedom
## Multiple R-squared:  0.5049, Adjusted R-squared:  0.4748 
## F-statistic: 16.79 on 15 and 247 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>If you look at the summary table of <strong>fit1</strong>, you can
see that the coefficient fo <strong>Hits</strong> is
<strong>7.82776155</strong>.</p>
<p>However, when we remove the <strong>AtBat</strong> variable from the
model, the corresponding coefficient for <strong>Hits</strong> is
<strong>1.88520</strong> and it becomes
<strong>insignificant</strong>.</p>
<p>Such a sharp change might be indication of multicollinearity.</p>
<p>To be ensure the appearance of multicollinearity in the analysis, we
have to use one formal way.</p>
<div id="section-variance-inflation-factor-vif" class="section level4">
<h4><span style="color:darkred"> Variance Inflation Factor (VIF)
</span></h4>
<p>The variance inflation factor (VIF) evaluates the extent of
correlation between one predictor and the other predictors in a model.
<strong>It estimates how much the variance of regression coefficient is
inflated due to multicollinearity in the model.</strong></p>
<p>It is used for diagnosing collinearity/multicollinearity. Higher
values signify that it is difficult to impossible to assess accurately
the contribution of predictors to a model.</p>
<p>If <span class="math inline">\(\text{VIF} &gt; 10\)</span>, then you
have a multicollinearity problem. In some sources, <span
class="math inline">\(&gt;5\)</span> might be accepted as a
multicollinearity treshold.</p>
<p>Go back and consider <strong>fit 1.</strong></p>
<p>To calculate VIF values without spending time by executing its
mathematical formula, use <code>car</code> package.</p>
<pre><code>library(car)
vif(fit1)</code></pre>
<pre><code>##      AtBat       Hits      HmRun       Runs        RBI      Walks      Years 
##  22.479369  30.083518   7.636705  15.117497  11.688503   4.090338   9.126253 
##     CAtBat      CHits     CHmRun      CRuns       CRBI     CWalks    PutOuts 
## 250.064625 495.652060  46.283619 158.681262 131.202332  19.730280   1.230378 
##    Assists     Errors 
##   2.700217   2.184223</code></pre>
<p>As you see, the model suffers from the multicollinearity problem
seriously. We have VIF values which is 495. It is incredible!</p>
</div>
</div>
<div id="section-remedies" class="section level2">
<h2><span style="color:darkred"> <strong>Remedies</strong> </span></h2>
<p>Although we suffer from multicollinearity, we have many number of
solutions, luckily.</p>
<p><span style="color:darkred"> <strong>Solutions</strong> </span></p>
<ul>
<li><p>Transformation on the dataset</p>
<ul>
<li>Application of centering, scaling etc.</li>
</ul></li>
<li><p>Dropping one or more predictors by intuition.</p>
<ul>
<li>Remove one variable of the related couple variables from the
model.</li>
</ul></li>
<li><p>Dropping one or more predictors by technique which are
<strong>backward elimination, stepwise selection or best subset
method</strong>.</p></li>
<li><p>Principle Component Analysis</p>
<ul>
<li>It produces uncorrelated components by rotation.</li>
</ul></li>
<li><p>Shrinkage Methods</p></li>
</ul>
<div id="section-shrinkageregularization-method" class="section level3">
<h3><span style="color:darkred"> <strong>Shrinkage/Regularization
Method</strong> </span></h3>
<p>The coefficient estimates in Linear Regression is generally obtained
by minimizing the residual sum of squares denoted as <span
class="math inline">\(RSS\)</span>.</p>
<p><span
class="math inline">\(\text{RSS}(\boldsymbol{\beta})=\sum_{i=1}^n(Y_i-\beta_0-\beta_1X_{i1}-\ldots-\beta_pX_{ip})^2.\)</span></p>
<p>The estimates by this optimization method denoted by <span
class="math inline">\(\hat{\beta}\)</span> are unbiased if the necessary
assumption is satisfied. In other words <span
class="math inline">\(\hat{\beta}\)</span> does not make any systematic
error in the estimation. However, bias is only one part of the quality
of an estimate: variance is also important. Indeed, the bias-variance
trade-off arises from the bias variance decomposition of the Mean
Squared Error (MSE) of an estimate.</p>
<p>The bias-variance trade-off is a fundamental concept in machine
learning that refers to the trade-off between two sources of error that
can occur when training a model: bias and variance.</p>
<p>Bias refers to the error that is introduced by a model’s tendency to
consistently underestimate or overestimate the true values of the target
variable. High bias can result in a model that is too simple and unable
to capture the underlying patterns in the data.</p>
<p>Variance, on the other hand, refers to the error that is introduced
by a model that is overly complex and that has learned to fit the noise
in the data, rather than the underlying patterns. High variance can
result in a model that is overfit to the training data and that does not
generalize well to new, unseen data.</p>
<p>The bias-variance trade-off occurs because reducing one type of error
often leads to an increase in the other. The goal in building a machine
learning model is to find the right balance between bias and variance
that results in the best overall performance on the task at hand.</p>
<div class="figure">
<img
src="https://raw.githubusercontent.com/ozancanozdemir/ozancanozdemir.github.io/master/biasvariance.png"
alt="" />
<p class="caption">CS109</p>
</div>
<p>Shrinkage methods involve altering the loss function of a model by
introducing an additional penalty term that discourages certain
characteristics of the model parameters.</p>
<p>Actually, it adds an amount of smart bias to <span
class="math inline">\(\hat{\beta}\)</span> in order to reduce its
variance, in such a way that we obtain simpler model and interpretations
from the biased version of <span
class="math inline">\(\hat{\beta}\)</span>. Also, it prevents model from
overfitting.</p>
<p>The Ridge and Lasso Methods are the shrinkage or regularization
methods used this idea in different ways.</p>
<p><span style="color:darkred"> <strong>Ridge Regression (L2
Regularization)</strong> </span></p>
<p>Ridge regression is similar to least squares except that the
coefficients are estimated by minimizing a slightly different quantity,
a loss function with a penalty term that is proportional to the square
of the parameters. Ridge regression, like OLS, seeks coefficient
estimates that reduce RSS, however they also have a shrinkage penalty
when the coefficients come closer to zero.</p>
<p><span
class="math inline">\(\text{RSS}(\boldsymbol{\beta})+\lambda\sum_{j=1}^p
\beta_j^2=\text{RSS}(\boldsymbol{\beta})+\lambda\|\boldsymbol\beta_{-1}\|_2^2\)</span></p>
<p>where <span class="math inline">\(\lambda\)</span> is penalty
parameter.</p>
<p>This penalty has the effect of shrinking the coefficient estimates
towards zero. Thus, we obtain simpler model with less weights. A
parameter, <span class="math inline">\(\lambda\)</span> , controls the
impact of the shrinking. While small value of <span
class="math inline">\(\lambda\)</span> may result in overfitting, a
large value of <span class="math inline">\(\lambda\)</span> will yield
underfitting, which refers to a model cannot capture the pattern in the
data properly. <span class="math inline">\(\lambda = 0\)</span> will
behave exactly like OLS regression and <span
class="math inline">\(\lambda = \infty\)</span> will produce all 0
coefficients, except intercept. Note that the behaviour of <span
class="math inline">\(\lambda\)</span> is valid for both lasso and
ridge.</p>
<p>Note that the shrinkage does not apply to the intercept.</p>
<p><strong>Why is ridge regression better than least
squares?</strong></p>
<p>The advantage is apparent in the bias variance tradeoff. As <span
class="math inline">\(\lambda\)</span> increases, the flexibility of the
ridge regression fit decreases. This leads to decrease variance, but
increased bias. Regular OLS regression is fixed with high variance, but
no bias. However, the lowest test MSE tends to occur at the intercept
between variance and bias. Thus, by properly tuning <span
class="math inline">\(\lambda\)</span> and acquiring less variance at
the cost of a small amount of bias, we can find a lower potential
MSE.</p>
<p>Ridge regression works best in situations for least squares estimates
have high variance. Ridge regression is also much more computationally
efficient that any subset method, since it is possible to simultaneously
solve for all values of <span
class="math inline">\(\lambda\)</span>.</p>
<p><strong>How to fit RR in R?</strong></p>
<p>We will use the <code>glmnet</code> package in order to perform ridge
regression and the lasso. The main function in this package is
<code>glmnet()</code>, which can be used to fit ridge regression models,
lasso models, and more. This function has slightly different syntax from
other model fitting functions that you have seen so far.</p>
<p>In particular, we must pass in an <strong>x matrix</strong> as well
as a <strong>y vector</strong>, and we do not use the <strong>y ~
x</strong> syntax.</p>
<p>We will now perform ridge regression and the lasso in order to
predict Salary on the Hitters data. As we stated, the data has no
missing values to perform ridge regression.</p>
<pre><code>x=model.matrix (Salary ∼.,Hitters )[,-1]
#minus sign is for removing the intercept
y=Hitters$Salary</code></pre>
<p>The <code>model.matrix()</code> function is particularly useful for
creating x, not only does it produce a matrix corresponding to the all
predictors but it also automatically transforms any qualitative
variables into dummy variables. The latter property is important because
<code>glmnet()</code> can only take numerical, quantitative inputs.</p>
<p>The <code>glmnet()</code> function has an alpha argument that
determines what type of model is fit. If <strong>alpha=0</strong> then a
ridge regression model is fit.</p>
<pre><code>library(glmnet)
grid =10^ seq (10,-2, length =100)
ridge.mod =glmnet (x,y,alpha =0, lambda =grid)</code></pre>
<p>By default the <code>glmnet()</code> function performs ridge
regression for an automatically selected range of <span
class="math inline">\(\lambda\)</span> values. However, here we have
chosen to implement the function over a grid of values ranging from
<span class="math inline">\(\lambda\)</span> = <span
class="math inline">\(10^{10}\)</span> to <span
class="math inline">\(\lambda\)</span> = <span
class="math inline">\(10^{-2}\)</span>, essentially covering the full
range of scenarios from the null model containing only the intercept, to
the least squares fit. As we will see, we can also compute model fits
for a particular value of <span class="math inline">\(\lambda\)</span>
that is not one of the original grid values.</p>
<p>Note that by default, the <code>glmnet()</code> function standardizes
the variables so that they are on the same scale. To turn off this
default setting, use the argument <code>standardize=FALSE</code></p>
<p>Associated with each value of <span
class="math inline">\(\lambda\)</span> is a vector of ridge regression
coefficients, stored in a matrix that can be accessed by
<code>coef()</code>.</p>
<pre><code>dim(coef(ridge.mod))</code></pre>
<pre><code>## [1]  17 100</code></pre>
<p>We expect the coefficient estimates to be much smaller, in terms of
<span class="math inline">\(l_2\)</span> norm, when a large value of
<span class="math inline">\(\lambda\)</span> is used, as compared to
when a small value of <span class="math inline">\(\lambda\)</span> is
used.</p>
<p>These are the coefficients when <span class="math inline">\(\lambda =
11498\)</span>, along with their <span
class="math inline">\(l_2\)</span> norm.</p>
<pre><code>ridge.mod$lambda[50]</code></pre>
<pre><code>## [1] 11497.57</code></pre>
<pre><code>coef(ridge.mod)[,50]</code></pre>
<pre><code>##   (Intercept)         AtBat          Hits         HmRun          Runs 
## 404.259816123   0.036988305   0.138354280   0.524805207   0.231107356 
##           RBI         Walks         Years        CAtBat         CHits 
##   0.240164596   0.289952867   1.108042412   0.003132353   0.011656495 
##        CHmRun         CRuns          CRBI        CWalks       PutOuts 
##   0.087564108   0.023393054   0.024142296   0.025034383   0.016492859 
##       Assists        Errors 
##   0.002627915  -0.020458095</code></pre>
<p>In contrast, here are the coefficients when <span
class="math inline">\(\lambda = 705\)</span>, along with their <span
class="math inline">\(l_2\)</span> norm. Note the much larger <span
class="math inline">\(l_2\)</span> norm of the coefficients associated
with this smaller value of <span
class="math inline">\(\lambda\)</span>.</p>
<pre><code>ridge.mod$lambda[60]</code></pre>
<pre><code>## [1] 705.4802</code></pre>
<pre><code>coef(ridge.mod)[,60]</code></pre>
<pre><code>## (Intercept)       AtBat        Hits       HmRun        Runs         RBI 
## 34.98376133  0.11025846  0.66029448  1.09050738  0.94787602  0.85694533 
##       Walks       Years      CAtBat       CHits      CHmRun       CRuns 
##  1.34141915  2.59711892  0.01082279  0.04685376  0.33407776  0.09427906 
##        CRBI      CWalks     PutOuts     Assists      Errors 
##  0.09747621  0.07346207  0.12010384  0.01778840 -0.66666032</code></pre>
<p>So, we have 100 times <span class="math inline">\(\lambda\)</span>
values, and 100 models. How to find the best <span
class="math inline">\(\lambda\)</span> values. Cross validation is
perhaps the simplest and most widely used method for that task.
<code>cv.glmnet</code> is the main function to do cross validation here,
along with various supporting methods such as plotting and prediction.
We still act on the sample data loaded before.</p>
<pre><code>set.seed(123)
cv_fit &lt;- cv.glmnet(x, y, alpha = 0, lambda = grid)</code></pre>
<pre><code>opt_lambda &lt;- cv_fit$lambda.min
opt_lambda</code></pre>
<pre><code>## [1] 4.641589</code></pre>
<p>The optimum <span class="math inline">\(\lambda\)</span> value for
the model is <code>opt_lambda</code>. In other words, the <span
class="math inline">\(\lambda\)</span> value where the model error is
minimum is <code>opt_lambda</code>.</p>
<p>If you run the cross validation without seed, you may get different
values for each run.</p>
<pre><code>plot(cv_fit)</code></pre>
<p><img src="Recitation4_files/figure-html/unnamed-chunk-27-1.png" width="624" /></p>
<pre><code>fit3 &lt;- glmnet(x, y, alpha = 0, lambda = opt_lambda) #best_ridge
coef(fit3)</code></pre>
<pre><code>## 17 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                       s0
## (Intercept) 101.09575314
## AtBat        -1.74838435
## Hits          5.67768815
## HmRun        -1.38693465
## Runs          0.19774943
## RBI           0.97495886
## Walks         4.99848835
## Years        -9.59507853
## CAtBat       -0.05939907
## CHits         0.16791484
## CHmRun        0.65118211
## CRuns         0.75210283
## CRBI          0.36577000
## CWalks       -0.54945457
## PutOuts       0.28926414
## Assists       0.29709130
## Errors       -3.41260868</code></pre>
<p>As expected, none of the coefficients are zero—ridge regression does
not perform variable selection. However, we can see how the estimated
coefficients change compared to linear model due to the
regularization.</p>
<pre><code>y_predicted &lt;- predict(fit3, s = opt_lambda, newx = x)

# Sum of Squares Total and Error
sst &lt;- sum((y - mean(y))^2)
sse &lt;- sum((y_predicted - y)^2)
</code></pre>
<pre><code>sst</code></pre>
<pre><code>## [1] 53319113</code></pre>
<pre><code>sse</code></pre>
<pre><code>## [1] 25607371</code></pre>
<p>Although ridge regression is very efficient tool against
multicollinearity, it has one important drawback. It includes all
predictors in the model. Although the penalty term will set many of them
close to zero, but never exactly equals to zero. This is not generally a
problem for prediction accuracy, but it can make the model more
difficult to interpret the results. Hence, we can consider another
technique.</p>
<p><span style="color:darkred"> <strong>Lasso Regression (L1
Regularization)</strong> </span></p>
<p>The penalizing equation for lasso is given below. Instead of adding a
penalty term being proportional to regression coefficients, it adds a
penalty term that is proportional to the absolute value of the
parameters, Lasso overcomes disadvantage mentioned above and is capable
of forcing some of the coefficients to zero granted that is large
enough. Thus, Lasso regression also performs variable selection.</p>
<p><span
class="math inline">\(\text{RSS}(\boldsymbol{\beta})+\lambda\sum_{j=1}^p
|\beta_j|=\text{RSS}(\boldsymbol{\beta})+\lambda\|\boldsymbol\beta_{-1}\|_1.\)</span>
where <span class="math inline">\(\lambda\)</span> is penalty
parameter.</p>
<p>In order to fit a lasso model, we once again use the
<code>glmnet()</code> function; however, this time we use the argument
<code>alpha=1.</code> Other than that change, we proceed just as we did
in fitting a ridge model.</p>
<pre><code>lasso.mod =glmnet (x,y,alpha =1, lambda =grid)
plot(lasso.mod)</code></pre>
<pre><code>## Warning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm):
## collapsing to unique &#39;x&#39; values</code></pre>
<p><img src="Recitation4_files/figure-html/unnamed-chunk-32-1.png" width="624" /></p>
<p>We can see from the coefficient plot that depending on the choice of
tuning parameter, some of the coefficients will be exactly equal to
zero. We now perform cross validation to find the optimal <span
class="math inline">\(\lambda\)</span> value and compute the associated
test error.</p>
<pre><code>set.seed(123)
cv.out =cv.glmnet (x,y,alpha =1, lambda =grid)</code></pre>
<pre><code>opt_lambda &lt;- cv.out$lambda.min
opt_lambda</code></pre>
<pre><code>## [1] 2.656088</code></pre>
<p>The optimum <span class="math inline">\(\lambda\)</span> value for
the model is <code>opt_lambda</code>. In other words, the <span
class="math inline">\(\lambda\)</span> value where the model error is
minimum is <code>opt_lambda</code>.</p>
<pre><code>plot(cv.out)</code></pre>
<p><img src="Recitation4_files/figure-html/unnamed-chunk-35-1.png" width="624" /></p>
<pre><code>fit4 &lt;- glmnet(x, y, alpha = 1, lambda = opt_lambda) #best_lasso
coef(fit4)</code></pre>
<pre><code>## 17 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                     s0
## (Intercept) 82.0413690
## AtBat       -1.7895636
## Hits         6.2411091
## HmRun        .        
## Runs         .        
## RBI          0.3000036
## Walks        4.8937753
## Years       -9.4759775
## CAtBat       .        
## CHits        .        
## CHmRun       0.5970981
## CRuns        0.7230100
## CRBI         0.3018570
## CWalks      -0.5239595
## PutOuts      0.2824997
## Assists      0.1997381
## Errors      -1.8423883</code></pre>
<pre><code>y_predicted_2 &lt;- predict(fit4, s = opt_lambda, newx = x)

# Sum of Squares Total and Error
sse_2 &lt;- sum((y_predicted_2 - y)^2)
sse_2</code></pre>
<pre><code>## [1] 25844294</code></pre>
<p>As you see, the prediction error among the models belong to Lasso
Regression. However, this method has also a drawback, unfortunately.</p>
<p>LASSO selects at most n variables for the dataset with small n and
large p. (n is the sample size, p is the number of variables in the
dataset.) It also selects only one variable among the a group of
correlated variables.</p>
<p><span style="color:darkred"> <strong>Elastic Net
Regression</strong></span></p>
<p>Elastic Net Regression (Friedman, Hastie, and Tibshirani 2010) is a
penalized linear modeling approach that is a mixture of ridge regression
(Hoerl and Kennard 1970), and least absolute shrinkage and selection
operator (LASSO) regression (Tibshirani 1996). Ridge regression reduces
the impact of collinearity on model parameters and LASSO reduces the
dimensionality of the support by shrinking some of the regression
coefficients to zero. Elastic net does both of these by solving the
following equation (for Gaussian responses):</p>
<p><span class="math inline">\(\text{RSS}(\boldsymbol{\beta})+\lambda
\left[ \left(1 - \alpha \right) \frac{\left \lVert \beta \right
\rVert_{2}^{2}}{2} + \alpha \left \lVert \beta \right \rVert_{1}
\right]\)</span></p>
<p>One of the challenges of using elastic net regression compared to
ridge and lasso regression is that it involves an additional
hyperparameter, <span class="math inline">\(\alpha\)</span>, which is
between 0 and 1, and needs to be tuned. However, this challenge can be
overcome by using the <code>cv.glmnet</code> function and testing a wide
range of alpha values. One way to accomplish this is to use a for loop
to iterate over a set of alpha values and then evaluate the performance
of the model for each alpha value using cross-validation. By doing so,
we can find the optimal alpha value that provides the best trade-off
between bias and variance in our model.</p>
<p>It is also possible to consider different packages like
<code>caret</code> but we try to be in <code>glmnet()</code>
package.</p>
<pre><code>lambda &lt;- c()
mse&lt;-c()
alpha&lt;-c()
for (i in 0:20) {
  alpha[i+1] &lt;- paste0(&quot;alpha&quot;, i/20)
  set.seed(123)
  opt_lambda_val &lt;-cv.glmnet(x,y, alpha=i/20)$lambda.min
  lambda[i+1]&lt;-opt_lambda_val
  fit&lt;-glmnet(x, y, alpha = i/20, lambda = opt_lambda_val)
  predicted&lt;-predict(fit, s = opt_lambda_val, newx = x)
  mse[i+1]&lt;-mean((y - predicted)^2)
}
comp_table&lt;-data.frame(lambda,mse,alpha)</code></pre>
<pre><code>comp_table</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["lambda"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["mse"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["alpha"],"name":[3],"type":["chr"],"align":["left"]}],"data":[{"1":"25.528210","2":"102375.13","3":"alpha0"},{"1":"4.761539","2":"97505.67","3":"alpha0.05"},{"1":"4.160462","2":"97354.86","3":"alpha0.1"},{"1":"4.024079","2":"97397.29","3":"alpha0.15"},{"1":"3.635263","2":"97308.54","3":"alpha0.2"},{"1":"3.191757","2":"97165.73","3":"alpha0.25"},{"1":"2.919125","2":"97094.09","3":"alpha0.3"},{"1":"2.746059","2":"97062.13","3":"alpha0.35"},{"1":"3.176363","2":"97446.22","3":"alpha0.4"},{"1":"3.098715","2":"97502.61","3":"alpha0.45"},{"1":"3.060752","2":"97580.95","3":"alpha0.5"},{"1":"3.351533","2":"97957.68","3":"alpha0.55"},{"1":"3.072239","2":"97808.55","3":"alpha0.6"},{"1":"3.112411","2":"97983.09","3":"alpha0.65"},{"1":"3.171876","2":"98223.72","3":"alpha0.7"},{"1":"3.249055","2":"98385.44","3":"alpha0.75"},{"1":"3.342969","2":"98537.57","3":"alpha0.8"},{"1":"3.146324","2":"98460.80","3":"alpha0.85"},{"1":"2.971528","2":"98394.09","3":"alpha0.9"},{"1":"2.815132","2":"98334.66","3":"alpha0.95"},{"1":"2.674375","2":"98282.44","3":"alpha1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre><code>best_alpha&lt;- comp_table$alpha[which.min(comp_table$mse)]</code></pre>
<pre><code>## [1] &quot;alpha0.35&quot;</code></pre>
<p>Here, the best result uses <span
class="math inline">\(\alpha=\)</span> <code>best_alpha</code>, so this
result is somewhere between ridge and lasso, but closer to ridge.</p>
<pre><code>el.mod =glmnet (x,y,alpha =0.35, lambda =grid)
plot(el.mod)</code></pre>
<p><img src="Recitation4_files/figure-html/unnamed-chunk-41-1.png" width="624" /></p>
<p>We can see from the coefficient plot that depending on the choice of
tuning parameter, some of the coefficients will be exactly equal to
zero. We now perform cross validation and compute the associated test
error.</p>
<pre><code>set.seed(123)
cv.out_1 =cv.glmnet (x,y,alpha =0.35, lambda =grid)</code></pre>
<pre><code>opt_lambda_e &lt;- cv.out_1$lambda.min
opt_lambda_e</code></pre>
<pre><code>## [1] 2.656088</code></pre>
<p>The optimum <span class="math inline">\(\lambda\)</span> value for
the model is <code>opt_lambda_e</code> . In other words, the <span
class="math inline">\(\lambda\)</span> value where the model error is
minimum is <code>opt_lambda_e</code>.</p>
<pre><code>plot(cv.out_1)</code></pre>
<p><img src="Recitation4_files/figure-html/unnamed-chunk-44-1.png" width="624" /></p>
<pre><code>fit5 &lt;- glmnet(x, y, alpha = 0.35, lambda = opt_lambda_e) #best_elastic
coef(fit5)</code></pre>
<pre><code>## 17 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                       s0
## (Intercept) 101.53831524
## AtBat        -1.89873159
## Hits          6.33803317
## HmRun        -0.02911485
## Runs         -0.07989281
## RBI           0.46115245
## Walks         5.16272662
## Years        -8.22169226
## CAtBat       -0.05537193
## CHits         0.05776477
## CHmRun        0.41037775
## CRuns         0.92595810
## CRBI          0.45425722
## CWalks       -0.59966347
## PutOuts       0.28983051
## Assists       0.28702554
## Errors       -2.74907651</code></pre>
<pre><code>y_predicted_3 &lt;- predict(fit5, s = opt_lambda_e, newx = x)

# Sum of Squares Total and Error
sse_3 &lt;- sum((y_predicted_3 - y)^2)
sse_3</code></pre>
<pre><code>## [1] 25510243</code></pre>
<p><span style="color:darkred"> <strong>Comparison</strong> </span></p>
<pre><code>coefmatrix&lt;-data.frame(as.matrix(coef(fit3)),as.matrix(coef(fit4)),as.matrix(coef(fit5)))
colnames(coefmatrix)&lt;-c(&quot;Ridge&quot;,&quot;Lasso&quot;,&quot;Elastic&quot;)
coefmatrix</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":[""],"name":["_rn_"],"type":[""],"align":["left"]},{"label":["Ridge"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Lasso"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Elastic"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"101.09575314","2":"82.0413690","3":"101.53831524","_rn_":"(Intercept)"},{"1":"-1.74838435","2":"-1.7895636","3":"-1.89873159","_rn_":"AtBat"},{"1":"5.67768815","2":"6.2411091","3":"6.33803317","_rn_":"Hits"},{"1":"-1.38693465","2":"0.0000000","3":"-0.02911485","_rn_":"HmRun"},{"1":"0.19774943","2":"0.0000000","3":"-0.07989281","_rn_":"Runs"},{"1":"0.97495886","2":"0.3000036","3":"0.46115245","_rn_":"RBI"},{"1":"4.99848835","2":"4.8937753","3":"5.16272662","_rn_":"Walks"},{"1":"-9.59507853","2":"-9.4759775","3":"-8.22169226","_rn_":"Years"},{"1":"-0.05939907","2":"0.0000000","3":"-0.05537193","_rn_":"CAtBat"},{"1":"0.16791484","2":"0.0000000","3":"0.05776477","_rn_":"CHits"},{"1":"0.65118211","2":"0.5970981","3":"0.41037775","_rn_":"CHmRun"},{"1":"0.75210283","2":"0.7230100","3":"0.92595810","_rn_":"CRuns"},{"1":"0.36577000","2":"0.3018570","3":"0.45425722","_rn_":"CRBI"},{"1":"-0.54945457","2":"-0.5239595","3":"-0.59966347","_rn_":"CWalks"},{"1":"0.28926414","2":"0.2824997","3":"0.28983051","_rn_":"PutOuts"},{"1":"0.29709130","2":"0.1997381","3":"0.28702554","_rn_":"Assists"},{"1":"-3.41260868","2":"-1.8423883","3":"-2.74907651","_rn_":"Errors"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre><code>sse_model&lt;-data.frame(sse,sse_2,sse_3)
colnames(sse_model)&lt;-c(&quot;Ridge&quot;,&quot;Lasso&quot;,&quot;Elastic&quot;)
sse_model</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Ridge"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["Lasso"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["Elastic"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"25607371","2":"25844294","3":"25510243"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>As seen, Elastic Net provides a model which has less error and ease
in interpretability.</p>
<p><strong>Which method is the best?</strong></p>
<p>Actually, it depends your purposes.</p>
<p>If you are interested in having less complex and more interpretable
model Lasso can be favorable.</p>
<p>If you are working with data with less number of variables which are
highly correlated, ridge can be appropriate.</p>
<p>If you would like to have a model that has the property of both lasso
and ridge, elastic net is an alternative.</p>
<p>If you are interested in having a model with accurate prediction,
then all of them are involved in the process.</p>
<div class="panel-heading tutorial-quiz-title"><span data-i18n="text.quiz">Quiz</span></div>
<div class="panel panel-default tutorial-question-container">
<div data-label="quiz46-1" class="tutorial-question panel-body">
<div id="quiz46-1-answer_container" class="shiny-html-output"></div>
<div id="quiz46-1-message_container" class="shiny-html-output"></div>
<div id="quiz46-1-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p><span
class="math inline">\(\sum_{i=1}^n\left(y_i-\beta_0-\sum_{j=1}^p \beta_j
x_{i j}\right)^2+\lambda \sum_{j=1}^p \beta_j^2\)</span></p>
<div class="panel-heading tutorial-quiz-title"><span data-i18n="text.quiz">Quiz</span></div>
<div class="panel panel-default tutorial-question-container">
<div data-label="quiz47-1" class="tutorial-question panel-body">
<div id="quiz47-1-answer_container" class="shiny-html-output"></div>
<div id="quiz47-1-message_container" class="shiny-html-output"></div>
<div id="quiz47-1-action_button_container" class="shiny-html-output"></div>
<script>if (Tutorial.triggerMathJax) Tutorial.triggerMathJax()</script>
</div>
</div>
<p><strong>Exercise</strong></p>
<p>Please click <a
href="http://users.metu.edu.tr/ozancan/e1.zip">here</a> to download your
exercise.</p>
<p><span style="color:darkred"> <strong>Reference</strong> </span></p>
<ul>
<li>Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani.
(2013). An introduction to statistical learning : with applications in
R. New York :Springer.</li>
</ul>
<p><span style="color:darkred"> <strong>Quiz 3</strong> </span></p>
<p><img
src="https://media.makeameme.org/created/something-is-coming-b69bb58577.jpg" />

<script type="application/shiny-prerendered" data-context="server-start">
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::prepare_tutorial_state(session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::i18n_observe_tutorial_language(input, session)
</script>


<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::event_trigger(session, "session_stop")
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "quiz44-1", question = structure("Which of the following statements best describes multicollinearity in linear regression?", html = TRUE, class = c("html", 
"character")), answers = list(structure(list(id = "lnr_ans_1f9d63f", 
    option = " It occurs when the dependent variable is strongly correlated with one of the independent variables", 
    value = " It occurs when the dependent variable is strongly correlated with one of the independent variables", 
    label = structure("It occurs when the dependent variable is strongly correlated with one of the independent variables", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_3a4d65d", 
    option = "It occurs when there is a perfect linear relationship between the dependent variable and one of the independent variables", 
    value = "It occurs when there is a perfect linear relationship between the dependent variable and one of the independent variables", 
    label = structure("It occurs when there is a perfect linear relationship between the dependent variable and one of the independent variables", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_acae8d", 
    option = "It occurs when there is a high degree of correlation between two or more independent variables.", 
    value = "It occurs when there is a high degree of correlation between two or more independent variables.", 
    label = structure("It occurs when there is a high degree of correlation between two or more independent variables.", html = TRUE, class = c("html", 
    "character")), correct = TRUE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_9d97f0e", 
    option = "It occurs when the residuals of the regression model are not normally distributed.", 
    value = "It occurs when the residuals of the regression model are not normally distributed.", 
    label = structure("It occurs when the residuals of the regression model are not normally distributed.", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
"character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
"character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
"character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
"character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
"character")), message = NULL, post_message = NULL), ids = list(
    answer = "quiz44-1-answer", question = "quiz44-1"), loading = NULL, 
    random_answer_order = FALSE, allow_retry = FALSE, seed = 310060667.855617, 
    options = list()), class = c("learnr_radio", "tutorial_question"
)), session = session)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "quiz45-1", question = structure("Which of the following methods can be used to detect multicollinearity in a linear regression model?", html = TRUE, class = c("html", 
"character")), answers = list(structure(list(id = "lnr_ans_660f32b", 
    option = " Scatter plots of the dependent variable against each independent variable.", 
    value = " Scatter plots of the dependent variable against each independent variable.", 
    label = structure("Scatter plots of the dependent variable against each independent variable.", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_a27dda", 
    option = "Calculation of the VIF (variance inflation factor) for each independent variable.", 
    value = "Calculation of the VIF (variance inflation factor) for each independent variable.", 
    label = structure("Calculation of the VIF (variance inflation factor) for each independent variable.", html = TRUE, class = c("html", 
    "character")), correct = TRUE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_e67bc2a", 
    option = "Checking the residuals of the regression model for normality.", 
    value = "Checking the residuals of the regression model for normality.", 
    label = structure("Checking the residuals of the regression model for normality.", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_8e9340f", 
    option = "Fitting the model with a different set of independent variables and comparing the results.", 
    value = "Fitting the model with a different set of independent variables and comparing the results.", 
    label = structure("Fitting the model with a different set of independent variables and comparing the results.", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
"character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
"character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
"character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
"character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
"character")), message = NULL, post_message = NULL), ids = list(
    answer = "quiz45-1-answer", question = "quiz45-1"), loading = NULL, 
    random_answer_order = FALSE, allow_retry = FALSE, seed = 578236897.230737, 
    options = list()), class = c("learnr_radio", "tutorial_question"
)), session = session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "quiz46-1", question = structure("The lasso, relative to least squares, is:", html = TRUE, class = c("html", 
"character")), answers = list(structure(list(id = "lnr_ans_ab349c3", 
    option = "More flexible and hence will give improved prediction accuracy\nwhen its increase in bias is less than its decrease in\nvariance.", 
    value = "More flexible and hence will give improved prediction accuracy\nwhen its increase in bias is less than its decrease in\nvariance.", 
    label = structure("More flexible and hence will give improved prediction accuracy\nwhen its increase in bias is less than its decrease in\nvariance.", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_6b3e128", 
    option = "More flexible and hence will give improved prediction accuracy\nwhen its increase in variance is less than its decrease\nin bias.", 
    value = "More flexible and hence will give improved prediction accuracy\nwhen its increase in variance is less than its decrease\nin bias.", 
    label = structure("More flexible and hence will give improved prediction accuracy\nwhen its increase in variance is less than its decrease\nin bias.", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_52c6bcd", 
    option = "Less flexible and hence will give improved prediction accuracy\nwhen its increase in bias is less than its decrease in\nvariance.", 
    value = "Less flexible and hence will give improved prediction accuracy\nwhen its increase in bias is less than its decrease in\nvariance.", 
    label = structure("Less flexible and hence will give improved prediction accuracy\nwhen its increase in bias is less than its decrease in\nvariance.", html = TRUE, class = c("html", 
    "character")), correct = TRUE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_d5d34ae", 
    option = "Less flexible and hence will give improved prediction accuracy\nwhen its increase in variance is less than its decrease\nin bias.", 
    value = "Less flexible and hence will give improved prediction accuracy\nwhen its increase in variance is less than its decrease\nin bias.", 
    label = structure("Less flexible and hence will give improved prediction accuracy\nwhen its increase in variance is less than its decrease\nin bias.", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
"character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
"character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
"character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
"character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
"character")), message = NULL, post_message = NULL), ids = list(
    answer = "quiz46-1-answer", question = "quiz46-1"), loading = NULL, 
    random_answer_order = FALSE, allow_retry = FALSE, seed = 308844749.356183, 
    options = list()), class = c("learnr_radio", "tutorial_question"
)), session = session)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::question_prerendered_chunk(structure(list(type = "learnr_radio", label = "quiz47-1", question = structure("Suppose we estimate the regression coefficients in a linear regression\nmodel by minimizing the quantity above for a particular value of lambda. As we increase lambda from 0, the training RSS will:", html = TRUE, class = c("html", 
"character")), answers = list(structure(list(id = "lnr_ans_315c62d", 
    option = "Increase initially, and then eventually start decreasing in an\ninverted U shape", 
    value = "Increase initially, and then eventually start decreasing in an\ninverted U shape", 
    label = structure("Increase initially, and then eventually start decreasing in an\ninverted U shape", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_e590aa9", 
    option = "Decrease initially, and then eventually start increasing in a\nU shape.", 
    value = "Decrease initially, and then eventually start increasing in a\nU shape.", 
    label = structure("Decrease initially, and then eventually start increasing in a\nU shape.", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_4ee0ec5", 
    option = "Steadily decrease.", value = "Steadily decrease.", 
    label = structure("Steadily decrease.", html = TRUE, class = c("html", 
    "character")), correct = FALSE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer")), structure(list(id = "lnr_ans_5d0143b", 
    option = "Steadily increase.", value = "Steadily increase.", 
    label = structure("Steadily increase.", html = TRUE, class = c("html", 
    "character")), correct = TRUE, message = NULL, type = "literal"), class = c("tutorial_question_answer", 
"tutorial_quiz_answer"))), button_labels = list(submit = structure("<span data-i18n=\"button.questionsubmit\">Submit Answer<\u002fspan>", html = TRUE, class = c("html", 
"character")), try_again = structure("<span data-i18n=\"button.questiontryagain\">Try Again<\u002fspan>", html = TRUE, class = c("html", 
"character"))), messages = list(correct = structure("Correct!", html = TRUE, class = c("html", 
"character")), try_again = structure("Incorrect", html = TRUE, class = c("html", 
"character")), incorrect = structure("Incorrect", html = TRUE, class = c("html", 
"character")), message = NULL, post_message = NULL), ids = list(
    answer = "quiz47-1-answer", question = "quiz47-1"), loading = NULL, 
    random_answer_order = FALSE, allow_retry = FALSE, seed = 1683512243.21605, 
    options = list()), class = c("learnr_radio", "tutorial_question"
)), session = session)
</script>
</p>
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.20"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.20"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.20"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.20"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.20"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["i18n"]},{"type":"character","attributes":{},"value":["21.6.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/i18n"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["i18next.min.js","tutorial-i18n-init.js"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["<script id=\"i18n-cstm-trns\" type=\"application/json\">{\"language\":\"en\",\"resources\":{\"en\":{\"translation\":{\"button\":{\"runcode\":\"Run Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Hint\",\"hint_plural\":\"Hints\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Next Hint\",\"hintprev\":\"Previous Hint\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copy to Clipboard\",\"startover\":\"Start Over\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continue\",\"submitanswer\":\"Submit Answer\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Previous Topic\",\"nexttopic\":\"Next Topic\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Try Again\"},\"text\":{\"startover\":\"Start Over\",\"areyousure\":\"Are you sure you want to start over? (all exercise progress will be reset)\",\"youmustcomplete\":\"You must complete the\",\"exercise\":\"exercise\",\"exercise_plural\":\"exercises\",\"inthissection\":\"in this section before continuing.\",\"code\":\"Code\",\"enginecap\":\"{{engine}} $t(text.code)\",\"quiz\":\"Quiz\",\"blank\":\"blank\",\"blank_plural\":\"blanks\",\"exercisecontainsblank\":\"This exercise contains {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Please replace {{blank}} with valid code.\",\"unparsable\":\"It looks like this might not be valid R code. R cannot determine how to turn your text into a complete command. You may have forgotten to fill in a blank, to remove an underscore, to include a comma between arguments, or to close an opening <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> or <code>{<\\/code> with a matching <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> or <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>It looks like your R code contains specially formatted quotation marks or &quot;curly&quot; quotes (<code>{{character}}<\\/code>) around character strings, making your code invalid. R requires character values to be contained in straight quotation marks (<code>&quot;<\\/code> or <code>'<\\/code>).<\\/p> {{code}} <p>Don't worry, this is a common source of errors when you copy code from another app that applies its own formatting to text. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. Try deleting the special character from your code and retyping it manually.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"and\":\"and\",\"or\":\"or\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"fr\":{\"translation\":{\"button\":{\"runcode\":\"Lancer le Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Indication\",\"hint_plural\":\"Indications\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Indication Suivante\",\"hintprev\":\"Indication Précédente\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copier dans le Presse-papier\",\"startover\":\"Recommencer\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuer\",\"submitanswer\":\"Soumettre\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Chapitre Précédent\",\"nexttopic\":\"Chapitre Suivant\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Réessayer\"},\"text\":{\"startover\":\"Recommencer\",\"areyousure\":\"Êtes-vous certains de vouloir recommencer? (La progression sera remise à zéro)\",\"youmustcomplete\":\"Vous devez d'abord compléter\",\"exercise\":\"l'exercice\",\"exercise_plural\":\"des exercices\",\"inthissection\":\"de cette section avec de continuer.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"et\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"es\":{\"translation\":{\"button\":{\"runcode\":\"Ejecutar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Pista\",\"hint_plural\":\"Pistas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Siguiente pista\",\"hintprev\":\"Pista anterior\",\"solution\":\"Solución\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar al portapapeles\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar respuesta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tema anterior\",\"nexttopic\":\"Tema siguiente\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Volver a intentar\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"¿De verdad quieres empezar de nuevo? (todo el progreso del ejercicio se perderá)\",\"youmustcomplete\":\"Debes completar\",\"exercise\":\"el ejercicio\",\"exercise_plural\":\"los ejercicios\",\"inthissection\":\"en esta sección antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Cuestionario\",\"and\":\"y\",\"or\":\"o\",\"oxfordcomma\":\"\"}}},\"pt\":{\"translation\":{\"button\":{\"runcode\":\"Executar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Dica\",\"hint_plural\":\"Dicas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Próxima dica\",\"hintprev\":\"Dica anterior\",\"solution\":\"Solução\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar para a área de transferência\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar resposta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tópico anterior\",\"nexttopic\":\"Próximo tópico\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tentar novamente\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"Tem certeza que deseja começar novamente? (todo o progresso feito será perdido)\",\"youmustcomplete\":\"Você deve completar\",\"exercise\":\"o exercício\",\"exercise_plural\":\"os exercícios\",\"inthissection\":\"nesta seção antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"e\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"tr\":{\"translation\":{\"button\":{\"runcode\":\"Çalıştırma Kodu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Ipucu\",\"hint_plural\":\"İpuçları\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Sonraki İpucu\",\"hintprev\":\"Önceki İpucu\",\"solution\":\"Çözüm\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Pano'ya Kopyala\",\"startover\":\"Baştan Başlamak\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Devam et\",\"submitanswer\":\"Cevabı onayla\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Önceki Konu\",\"nexttopic\":\"Sonraki Konu\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tekrar Deneyin\"},\"text\":{\"startover\":\"Baştan Başlamak\",\"areyousure\":\"Baştan başlamak istediğinizden emin misiniz? (tüm egzersiz ilerlemesi kaybolacak)\",\"youmustcomplete\":\"Tamamlamalısın\",\"exercise\":\"egzersiz\",\"exercise_plural\":\"egzersizler\",\"inthissection\":\"devam etmeden önce bu bölümde\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Sınav\",\"oxfordcomma\":\"\"}}},\"emo\":{\"translation\":{\"button\":{\"runcode\":\"<U+0001F3C3>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+0001F4A1>\",\"hint_plural\":\"$t(button.hint)\",\"hinttitle\":\"$t(button.hint)\",\"solution\":\"<U+0001F3AF>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+0001F4CB>\",\"startover\":\"<U+23EE>\",\"startovertitle\":\"Start Over\",\"continue\":\"<U+2705>\",\"submitanswer\":\"<U+0001F197>\",\"submitanswertitle\":\"Submit Answer\",\"previoustopic\":\"<U+2B05>\",\"nexttopic\":\"<U+27A1>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+0001F501>\"},\"text\":{\"startover\":\"<U+23EE>\",\"areyousure\":\"<U+0001F914>\",\"youmustcomplete\":\"<U+26A0><U+FE0F> <U+0001F449> <U+0001F9D1><U+200D><U+0001F4BB>\",\"exercise\":\"\",\"exercise_plural\":\"\",\"inthissection\":\"\",\"code\":\"<U+0001F4BB>\",\"enginecap\":\"$t(text.code) {{engine}}\",\"oxfordcomma\":\"\"}}},\"eu\":{\"translation\":{\"button\":{\"runcode\":\"Kodea egikaritu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Laguntza\",\"hint_plural\":\"Laguntza\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Aurreko laguntza\",\"hintprev\":\"Hurrengo laguntza\",\"solution\":\"Ebazpena\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Arbelean kopiatu\",\"startover\":\"Berrabiarazi\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Jarraitu\",\"submitanswer\":\"Erantzuna bidali\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Aurreko atala\",\"nexttopic\":\"Hurrengo atala\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Berriro saiatu\"},\"text\":{\"startover\":\"Berrabiarazi\",\"areyousure\":\"Berriro hasi nahi duzu? (egindako lana galdu egingo da)\",\"youmustcomplete\":\"Aurrera egin baino lehen atal honetako\",\"exercise\":\"ariketa egin behar duzu.\",\"exercise_plural\":\"ariketak egin behar dituzu.\",\"inthissection\":\"\",\"code\":\"Kodea\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Galdetegia\",\"oxfordcomma\":\"\"}}},\"de\":{\"translation\":{\"button\":{\"runcode\":\"Code ausführen\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Tipp\",\"hint_plural\":\"Tipps\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nächster Tipp\",\"hintprev\":\"Vorheriger Tipp\",\"solution\":\"Lösung\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"In die Zwischenablage kopieren\",\"startover\":\"Neustart\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Weiter\",\"submitanswer\":\"Antwort einreichen\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Vorheriges Kapitel\",\"nexttopic\":\"Nächstes Kapitel\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Nochmal versuchen\"},\"text\":{\"startover\":\"Neustart\",\"areyousure\":\"Bist du sicher, dass du neustarten willst? (der gesamte Lernfortschritt wird gelöscht)\",\"youmustcomplete\":\"Vervollstädinge\",\"exercise\":\"die Übung\",\"exercise_plural\":\"die Übungen\",\"inthissection\":\"in diesem Kapitel, bevor du fortfährst.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"Lücke\",\"blank_plural\":\"Lücken\",\"pleasereplaceblank\":\"Bitte ersetze {{blank}} mit gültigem Code.\",\"unparsable\":\"Dies scheint kein gültiger R Code zu sein. R kann deinen Text nicht in einen gültigen Befehl übersetzen. Du hast vielleicht vergessen, die Lücke zu füllen, einen Unterstrich zu entfernen, ein Komma zwischen Argumente zu setzen oder ein eröffnendes <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> oder <code>{<\\/code> mit einem zugehörigen <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> oder <code>}<\\/code> zu schließen.\\n\",\"and\":\"und\",\"or\":\"oder\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"ko\":{\"translation\":{\"button\":{\"runcode\":\"<U+CF54><U+B4DC> <U+C2E4><U+D589>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+D78C><U+D2B8>\",\"hint_plural\":\"<U+D78C><U+D2B8><U+B4E4>\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"<U+B2E4><U+C74C> <U+D78C><U+D2B8>\",\"hintprev\":\"<U+C774><U+C804> <U+D78C><U+D2B8>\",\"solution\":\"<U+C194><U+B8E8><U+C158>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+D074><U+B9BD><U+BCF4><U+B4DC><U+C5D0> <U+BCF5><U+C0AC>\",\"startover\":\"<U+C7AC><U+D559><U+C2B5>\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"<U+B2E4><U+C74C> <U+D559><U+C2B5><U+C73C><U+B85C>\",\"submitanswer\":\"<U+C815><U+B2F5> <U+C81C><U+CD9C>\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"<U+C774><U+C804> <U+D1A0><U+D53D>\",\"nexttopic\":\"<U+B2E4><U+C74C> <U+D1A0><U+D53D>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+C7AC><U+C2DC><U+B3C4>\"},\"text\":{\"startover\":\"<U+C7AC><U+D559><U+C2B5>\",\"areyousure\":\"<U+B2E4><U+C2DC> <U+C2DC><U+C791> <U+D558><U+C2DC><U+ACA0><U+C2B5><U+B2C8><U+AE4C>? (<U+BAA8><U+B4E0> <U+C608><U+C81C><U+C758> <U+C9C4><U+D589> <U+C815><U+BCF4><U+AC00> <U+C7AC><U+C124><U+C815><U+B429><U+B2C8><U+B2E4>)\",\"youmustcomplete\":\"<U+B2F9><U+C2E0><U+C740> <U+C644><U+B8CC><U+D574><U+C57C> <U+D569><U+B2C8><U+B2E4>\",\"exercise\":\"<U+C5F0><U+C2B5><U+BB38><U+C81C>\",\"exercise_plural\":\"<U+C5F0><U+C2B5><U+BB38><U+C81C><U+B4E4>\",\"inthissection\":\"<U+C774> <U+C139><U+C158><U+C744> <U+C2E4><U+D589><U+D558><U+AE30> <U+C804><U+C5D0>\",\"code\":\"<U+CF54><U+B4DC>\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"<U+D034><U+C988>\",\"blank\":\"<U+ACF5><U+BC31>\",\"blank_plural\":\"<U+ACF5><U+BC31><U+B4E4>\",\"exercisecontainsblank\":\"<U+C774> <U+C5F0><U+C2B5><U+BB38><U+C81C><U+C5D0><U+B294> {{count}}<U+AC1C><U+C758> $t(text.blank)<U+C774> <U+D3EC><U+D568><U+B418><U+C5B4> <U+C788><U+C2B5><U+B2C8><U+B2E4>.\",\"pleasereplaceblank\":\"{{blank}}<U+B97C> <U+C720><U+D6A8><U+D55C> <U+CF54><U+B4DC><U+B85C> <U+BC14><U+AFB8><U+C2ED><U+C2DC><U+C624>.\",\"unparsable\":\"<U+C774><U+AC83><U+C740> <U+C720><U+D6A8><U+D55C> R <U+CF54><U+B4DC><U+AC00> <U+C544><U+B2D0> <U+C218> <U+C788><U+C2B5><U+B2C8><U+B2E4>. R<U+C740> <U+D14D><U+C2A4><U+D2B8><U+B97C> <U+C644><U+C804><U+D55C> <U+BA85><U+B839><U+C73C><U+B85C> <U+BCC0><U+D658><U+D558><U+B294> <U+BC29><U+BC95><U+C744> <U+ACB0><U+C815><U+D560> <U+C218> <U+C5C6><U+C2B5><U+B2C8><U+B2E4>. <U+B2F9><U+C2E0><U+C740> <U+ACF5><U+BC31><U+C774><U+B098> <U+BC11><U+C904><U+C744> <U+B300><U+CCB4><U+D558><U+C5EC> <U+CC44><U+C6B0><U+AE30>, <U+C778><U+C218><U+B97C> <U+CEF4><U+B9C8><U+B85C> <U+AD6C><U+BD84><U+D558><U+AE30>, <U+B610><U+B294> <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> , <code>{<\\/code><U+B85C> <U+C2DC><U+C791><U+D558><U+B294> <U+AD6C><U+BB38><U+C744> <U+B2EB><U+B294> <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>, <code>}<\\/code><U+C744> <U+C78A><U+C5C8><U+C744> <U+C218><U+B3C4> <U+C788><U+C2B5><U+B2C8><U+B2E4>.\\n\",\"and\":\"<U+ADF8><U+B9AC><U+ACE0>\",\"or\":\"<U+D639><U+C740>\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}},\"zh\":{\"translation\":{\"button\":{\"runcode\":\"<U+8FD0><U+884C><U+4EE3><U+7801>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+63D0><U+793A>\",\"hint_plural\":\"<U+63D0><U+793A>\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"<U+4E0B><U+4E00><U+4E2A><U+63D0><U+793A>\",\"hintprev\":\"<U+4E0A><U+4E00><U+4E2A><U+63D0><U+793A>\",\"solution\":\"<U+7B54><U+6848>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+590D><U+5236><U+5230><U+526A><U+5207><U+677F>\",\"startover\":\"<U+91CD><U+65B0><U+5F00><U+59CB>\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"<U+7EE7><U+7EED>\",\"submitanswer\":\"<U+63D0><U+4EA4><U+7B54><U+6848>\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"<U+4E0A><U+4E00><U+4E13><U+9898>\",\"nexttopic\":\"<U+4E0B><U+4E00><U+4E13><U+9898>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+518D><U+8BD5><U+4E00><U+6B21>\"},\"text\":{\"startover\":\"<U+91CD><U+7F6E>\",\"areyousure\":\"<U+4F60><U+786E><U+5B9A><U+8981><U+91CD><U+65B0><U+5F00><U+59CB><U+5417>? (<U+6240><U+6709><U+5F53><U+524D><U+8FDB><U+5EA6><U+5C06><U+88AB><U+91CD><U+7F6E>)\",\"youmustcomplete\":\"<U+4F60><U+5FC5><U+987B><U+5B8C><U+6210>\",\"exercise\":\"<U+7EC3><U+4E60>\",\"exercise_plural\":\"<U+7EC3><U+4E60>\",\"inthissection\":\"<U+5728><U+8FDB><U+884C><U+672C><U+8282><U+4E4B><U+524D>\",\"code\":\"<U+4EE3><U+7801>\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"<U+6D4B><U+8BD5>\",\"blank\":\"<U+7A7A>\",\"blank_plural\":\"<U+7A7A>\",\"exercisecontainsblank\":\"<U+672C><U+7EC3><U+4E60><U+5305><U+542B>{{count}}<U+4E2A>$t(text.blank)\",\"pleasereplaceblank\":\"<U+8BF7><U+5728>{{blank}}<U+5185><U+586B><U+5199><U+6070><U+5F53><U+7684><U+4EE3><U+7801>\",\"unparsable\":\"<U+8FD9><U+4F3C><U+4E4E><U+4E0D><U+662F><U+6709><U+6548><U+7684>R<U+4EE3><U+7801><U+3002> R<U+4E0D><U+77E5><U+9053><U+5982><U+4F55><U+5C06><U+60A8><U+7684><U+6587><U+672C><U+8F6C><U+6362><U+4E3A><U+5B8C><U+6574><U+7684><U+547D><U+4EE4><U+3002> <U+60A8><U+662F><U+5426><U+5FD8><U+4E86><U+586B><U+7A7A>,<U+5FD8><U+4E86><U+5220><U+9664><U+4E0B><U+5212><U+7EBF>,<U+5FD8><U+4E86><U+5728><U+53C2><U+6570><U+4E4B><U+95F4><U+5305><U+542B><U+9017><U+53F7>,<U+6216><U+8005><U+662F><U+5FD8><U+4E86><U+7528><code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>,<code>}<\\/code><U+6765><U+5C01><U+95ED><code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code><U+3002> or <code>{<\\/code><U+3002>\\n\",\"unparsablequotes\":\"<p><U+60A8><U+7684>R<U+4EE3><U+7801><U+4E2D><U+4F3C><U+4E4E><U+542B><U+6709><U+7279><U+6B8A><U+683C><U+5F0F><U+7684><U+5F15><U+53F7>,<U+6216><U+8005><U+5F2F><U+5F15><U+53F7>(<code>{{character}}<\\/code>) <U+5728><U+5B57><U+7B26><U+4E32><U+524D><U+540E>,<U+5728>R<U+4E2D><U+5B57><U+7B26><U+4E32><U+5E94><U+8BE5><U+88AB><U+76F4><U+5F15><U+53F7>(<code>&quot;<\\/code> <U+6216><U+8005> <code>'<\\/code>)<U+5305><U+88F9><U+3002><\\/p> {{code}} <p><U+522B><U+62C5><U+5FC3>,<U+8BE5><U+9519><U+8BEF><U+7ECF><U+5E38><U+5728><U+590D><U+5236><U+7C98><U+8D34><U+5305><U+542B><U+683C><U+5F0F><U+7684><U+4EE3><U+7801><U+65F6><U+9047><U+5230>, <U+60A8><U+53EF><U+4EE5><U+5C1D><U+8BD5><U+5C06><U+8BE5><U+884C><U+4E2D><U+7684><U+4EE3><U+7801><U+66FF><U+6362><U+4E3A><U+4EE5><U+4E0B><U+4EE3><U+7801>,<U+4E5F><U+8BB8><U+8FD8><U+6709><U+5176><U+4ED6><U+5730><U+65B9><U+9700><U+8981><U+4FEE><U+6539><U+3002><\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p><U+60A8><U+7684><U+4EE3><U+7801><U+4E2D><U+4F3C><U+4E4E><U+5305><U+542B><U+6709><U+5F02><U+5E38><U+5B57><U+7B26>(<code>{{character}}<\\/code>),<U+5BFC><U+81F4><U+4EE3><U+7801><U+65E0><U+6548><U+3002><\\/p> {{code}} <p><U+6709><U+65F6><U+5019><U+4F60><U+7684><U+4EE3><U+7801><U+53EF><U+80FD><U+542B><U+6709><U+770B><U+4F3C><U+6B63><U+5E38><U+5B57><U+7B26><U+7684><U+7279><U+6B8A><U+5B57><U+7B26>,<U+7279><U+522B><U+662F><U+5F53><U+4F60><U+590D><U+5236><U+7C98><U+8D34><U+5176><U+4ED6><U+6765><U+6E90><U+4EE3><U+7801><U+7684><U+65F6><U+5019><U+3002> <U+8BF7><U+8BD5><U+7740><U+5220><U+9664><U+8FD9><U+4E9B><U+7279><U+6B8A><U+5B57><U+7B26>,<U+91CD><U+65B0><U+8F93><U+5165><\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p><U+60A8><U+7684><U+4EE3><U+7801><U+4E2D><U+4F3C><U+4E4E><U+5305><U+542B><U+6709><U+5F02><U+5E38><U+5B57><U+7B26>(<code>{{character}}<\\/code>),<U+5BFC><U+81F4><U+4EE3><U+7801><U+65E0><U+6548><U+3002><\\/p> {{code}} <p><U+6709><U+65F6><U+5019><U+4F60><U+7684><U+4EE3><U+7801><U+53EF><U+80FD><U+542B><U+6709><U+770B><U+4F3C><U+6B63><U+5E38><U+5B57><U+7B26><U+7684><U+7279><U+6B8A><U+5B57><U+7B26>,<U+7279><U+522B><U+662F><U+5F53><U+4F60><U+590D><U+5236><U+7C98><U+8D34><U+5176><U+4ED6><U+6765><U+6E90><U+4EE3><U+7801><U+7684><U+65F6><U+5019><U+3002> <U+8BF7><U+8BD5><U+7740><U+5220><U+9664><U+8FD9><U+4E9B><U+7279><U+6B8A><U+5B57><U+7B26>,<U+91CD><U+65B0><U+8F93><U+5165><\\/p>\\n\",\"and\":\"<U+4E14>\",\"or\":\"<U+6216>\",\"listcomma\":\",\",\"oxfordcomma\":\",\"}}},\"pl\":{\"translation\":{\"button\":{\"runcode\":\"Uruchom kod\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Podpowiedz\",\"hint_plural\":\"Podpowiedzi\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nastepna podpowiedz\",\"hintprev\":\"Poprzednia podpowiedz\",\"solution\":\"Rozwiazanie\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Kopiuj do schowka\",\"startover\":\"Zacznij od poczatku\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Kontynuuj\",\"submitanswer\":\"Wyslij\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Poprzednia sekcja\",\"nexttopic\":\"Nastepna sekcja\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Spróbuj ponownie\"},\"text\":{\"startover\":\"Zacznij od poczatku\",\"areyousure\":\"Czy na pewno chcesz zaczac od poczatku? (caly postep w zadaniu zostanie utracony)\",\"youmustcomplete\":\"Musisz ukonczyc\",\"exercise\":\"cwiczenie\",\"exercise_plural\":\"cwiczenia\",\"inthissection\":\"w tej sekcji przed kontynuowaniem\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"luka\",\"blank_plural\":\"luk(i)\",\"exercisecontainsblank\":\"To cwiczenie zawiera {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Prosze uzupelnic {{blank}} prawidlowym kodem.\",\"unparsable\":\"Wyglada na to, ze moze to nie byc prawidlowy kod R. R nie jest w stanie przetworzyc Twojego tekstu na polecenie. Mogles(-as) zapomniec wypelnic luki, usunac podkreslnik, umiescic przecinka miedzy argumentami, lub zamknac znak <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> lub <code>{<\\/code> odpowiadajacym <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> lub <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>Wyglada na to, ze Twój kod zawiera szczególnie sformatowane cudzyslowy lub cudzyslowy typograficzne (<code>{{character}}<\\/code>) przy ciagach znaków, co sprawia, ze kod jest niepoprawny. R wymaga cudzyslowów prostych (<code>&quot;<\\/code> albo <code>'<\\/code>).<\\/p> {{code}} <p>Nie martw sie, to powszechne zródlo bledów, gdy kopiuje sie kod z innego programu, który sam formatuje teskt. Mozesz spróbowac zastapic swój kod nastepujacym kodem. Moga byc tez inne miejsca, które wymagaja poprawienia.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>Wyglada na to, ze Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, ze kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod moze zawierac znak specjalny, który wyglada jak zwykly znak, zwlaszcza jesli kopiujesz kod z innego programu. Spróbuj usunac znak specjalny i wpisac do ponownie recznie.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>Wyglada na to, ze Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, ze kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod moze zawierac znak specjalny, który wyglada jak zwykly znak, zwlaszcza jesli kopiujesz kod z innego programu. Mozesz spróbowac zastapic swój kod nastepujacym kodem. Moga byc tez inne miejsca, które wymagaja poprawienia.<\\/p> {{suggestion}}\\n\",\"and\":\"i\",\"or\":\"lub\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}}}}<\/script>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.11.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.20"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.20"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.20"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["5.5.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.11.2"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.2"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86]}},"value":[{"type":"character","attributes":{},"value":["abind","backports","base","bslib","cachem","car","carData","checkmate","cli","codetools","colorspace","commonmark","compiler","corrplot","curl","datasets","digest","dplyr","ellipsis","evaluate","fansi","farver","fastmap","foreach","generics","GGally","ggplot2","glmnet","glue","graphics","grDevices","grid","gtable","highr","htmltools","htmlwidgets","httpuv","ISLR","iterators","jquerylib","jsonlite","knitr","labeling","later","lattice","learnr","lifecycle","magrittr","markdown","Matrix","methods","mime","munsell","PerformanceAnalytics","pillar","pkgconfig","plyr","promises","quadprog","R6","RColorBrewer","Rcpp","reshape","rlang","rmarkdown","rprojroot","rstudioapi","sass","scales","shape","shiny","splines","stats","survival","tibble","tidyselect","tools","utf8","utils","vctrs","withr","xfun","xtable","xts","yaml","zoo"]},{"type":"character","attributes":{},"value":["1.4-5","1.4.1","4.1.0","0.4.2","1.0.6","3.1-1","3.0-5","2.1.0","3.4.1","0.2-19","2.0-2","1.8.1","4.1.0","0.92","5.0.0","4.1.0","0.6.31","1.1.0","0.3.2","0.20","0.5.0","2.1.1","1.1.0","1.5.2","0.1.3","2.1.2","3.4.1","4.1-6","1.6.2","4.1.0","4.1.0","4.1.0","0.3.1","0.10","0.5.4","1.6.1","1.6.9","1.4","1.0.14","0.1.4","1.7.2","1.42","0.4.2","1.3.0","0.20-45","0.11.2","1.0.3","2.0.1","1.5","1.3-4","4.1.0","0.12","0.5.0","2.0.4","1.8.1","2.0.3","1.8.8","1.2.0.1","1.5-8","2.5.1","1.1-3","1.0.7","0.8.9","1.0.6","2.20","2.0.3","0.14","0.4.5","1.2.1","1.4.6","1.7.4","4.1.0","4.1.0","3.5-3","3.1.6","1.2.0","4.1.0","1.2.2","4.1.0","0.5.2","2.5.0","0.37","1.8-4","0.13.0","2.3.7","1.8-11"]}]}]}
</script>
<!--/html_preserve-->
</div>
</div>

</article> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h1 class="title toc-ignore" style="display:none;">STAT 412-Recitation
4</h1>
<h4 class="author"><em>Ozancan Ozdemir</em></h4>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</main> <!-- bandContent page -->
</div> <!-- pageContent band -->



<!-- Build Tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
